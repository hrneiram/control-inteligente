# Gu√≠a Extensa de Entrenamiento Iterativo del Modelo Neuronal

Esta gu√≠a detalla el proceso completo de entrenamiento, compilaci√≥n e iteraci√≥n para mejorar el rendimiento del controlador neuronal de TurtleSim.

---

## Tabla de Contenidos

1. [Flujo de Trabajo Completo](#flujo-de-trabajo-completo)
2. [Entrenamiento del Modelo](#entrenamiento-del-modelo)
3. [Compilaci√≥n y Despliegue](#compilaci√≥n-y-despliegue)
4. [Evaluaci√≥n y An√°lisis](#evaluaci√≥n-y-an√°lisis)
5. [Iteraci√≥n y Mejora](#iteraci√≥n-y-mejora)
6. [Ajuste de Hiperpar√°metros](#ajuste-de-hiperpar√°metros)
7. [Mejora de Datos de Entrenamiento](#mejora-de-datos-de-entrenamiento)
8. [Debugging y Soluci√≥n de Problemas](#debugging-y-soluci√≥n-de-problemas)
9. [Checklist de Mejora Continua](#checklist-de-mejora-continua)

---

## Flujo de Trabajo Completo

### Diagrama del Proceso

```
1. Modificar par√°metros/datos
   ‚Üì
2. Entrenar modelo
   ‚Üì
3. Compilar paquete
   ‚Üì
4. Copiar modelo
   ‚Üì
5. Ejecutar y observar
   ‚Üì
6. Analizar comportamiento
   ‚Üì
7. Identificar problemas
   ‚Üì
8. Volver al paso 1
```

---

## Entrenamiento del Modelo

### Paso 1: Preparar el Entorno

```bash
# Dentro del contenedor Docker
cd /ros2_ws/src/turtle_nn_control/turtle_nn_control
```

### Paso 2: Entrenar el Modelo B√°sico

```bash
python3 train_nn_model.py
```

**Par√°metros por defecto:**
- Muestras: 5000
- √âpocas: 100
- Batch size: 32
- Learning rate: 0.001

### Paso 3: Entrenar con Par√°metros Personalizados

Puedes modificar `train_nn_model.py` para cambiar los par√°metros:

```python
# En la funci√≥n main(), cambiar:
trained_model = train_model(
    model, 
    inputs, 
    targets, 
    epochs=200,        # M√°s √©pocas para mejor convergencia
    batch_size=64,    # Batch m√°s grande para estabilidad
    learning_rate=0.0005  # Learning rate m√°s bajo para fine-tuning
)
```

### Paso 4: Verificar el Entrenamiento

Observa la salida del entrenamiento:

```
√âpoca 10/100, P√©rdida promedio: 0.260246
√âpoca 20/100, P√©rdida promedio: 0.146833
...
√âpoca 100/100, P√©rdida promedio: 0.045450
```

**Indicadores de buen entrenamiento:**
- ‚úÖ P√©rdida disminuye consistentemente
- ‚úÖ P√©rdida final < 0.1 (idealmente < 0.05)
- ‚úÖ No hay sobreajuste (p√©rdida no aumenta al final)

**Se√±ales de problemas:**
- ‚ùå P√©rdida no disminuye: learning rate muy bajo o arquitectura insuficiente
- ‚ùå P√©rdida aumenta: learning rate muy alto
- ‚ùå P√©rdida oscila: batch size muy peque√±o

---

## Compilaci√≥n y Despliegue

### M√©todo 1: Script Automatizado (Recomendado)

```bash
cd /ros2_ws
./src/turtle_nn_control/rebuild_and_setup.sh
source install/setup.bash
```

### M√©todo 2: Manual (Paso a Paso)

```bash
# 1. Ir al workspace
cd /ros2_ws

# 2. Recompilar el paquete
colcon build --packages-select turtle_nn_control

# 3. Verificar que el modelo existe
ls -la src/turtle_nn_control/turtle_nn_control/turtle_nn_model.pth

# 4. Copiar el modelo al directorio de instalaci√≥n
mkdir -p install/turtle_nn_control/lib/python3.10/site-packages/turtle_nn_control
cp src/turtle_nn_control/turtle_nn_control/turtle_nn_model.pth \
   install/turtle_nn_control/lib/python3.10/site-packages/turtle_nn_control/

# 5. Recargar el entorno
source install/setup.bash

# 6. Verificar que el modelo se puede cargar
python3 -c "import torch; print('PyTorch OK'); m = torch.load('install/turtle_nn_control/lib/python3.10/site-packages/turtle_nn_control/turtle_nn_model.pth'); print('Modelo OK')"
```

### Verificaci√≥n R√°pida

```bash
# Verificar que el paquete est√° instalado
ros2 pkg list | grep turtle_nn_control

# Verificar que el ejecutable existe
ros2 run turtle_nn_control nn_controller --help
```

---

## Evaluaci√≥n y An√°lisis

### Paso 1: Ejecutar el Simulador

**Terminal 1:**
```bash
ros2 run turtlesim turtlesim_node
```

### Paso 2: Ejecutar el Controlador

**Terminal 2:**
```bash
source /opt/ros/humble/setup.bash
source /ros2_ws/install/setup.bash
ros2 run turtle_nn_control nn_controller
```

### Paso 3: Observar el Comportamiento

**M√©tricas a observar:**

1. **Navegaci√≥n hacia objetivos:**
   - ‚úÖ ¬øLlega a los objetivos de forma directa?
   - ‚úÖ ¬øTarda mucho tiempo?
   - ‚úÖ ¬øHace movimientos innecesarios?

2. **Evitaci√≥n de obst√°culos:**
   - ‚úÖ ¬øSe desv√≠a a tiempo?
   - ‚úÖ ¬øMantiene distancia segura?
   - ‚ùå ¬øChoca con obst√°culos?
   - ‚ùå ¬øSe queda atascado cerca de obst√°culos?

3. **Suavidad del movimiento:**
   - ‚úÖ ¬øMovimientos fluidos?
   - ‚ùå ¬øMovimientos bruscos o err√°ticos?
   - ‚ùå ¬øOscilaciones?

### Paso 4: Registrar Observaciones

Crea un archivo de log para cada iteraci√≥n:

```bash
# Crear directorio de logs
mkdir -p /ros2_ws/training_logs

# Registrar observaciones
cat > /ros2_ws/training_logs/iteracion_01.md << EOF
# Iteraci√≥n 01 - [Fecha]

## Par√°metros de Entrenamiento
- √âpocas: 100
- Batch size: 32
- Learning rate: 0.001
- Muestras: 5000

## Observaciones
- ‚úÖ Llega a objetivos correctamente
- ‚ùå A veces no se desv√≠a de obst√°culos
- ‚ùå Movimientos un poco bruscos cerca de obst√°culos

## Problemas Identificados
1. El modelo no prioriza suficiente la evitaci√≥n cuando el obst√°culo est√° en la trayectoria
2. La velocidad angular es demasiado alta en algunas situaciones

## Pr√≥ximos Pasos
1. Aumentar peso de evitaci√≥n en datos de entrenamiento
2. Reducir velocidad angular m√°xima en reglas heur√≠sticas
EOF
```

---

## Iteraci√≥n y Mejora

### Ciclo de Iteraci√≥n Recomendado

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 1. Identificar problema        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 2. Modificar datos/par√°metros  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 3. Entrenar nuevo modelo       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 4. Compilar y desplegar        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 5. Evaluar comportamiento       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 6. Comparar con iteraci√≥n prev ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚Üì
         ¬øMejor√≥?
         /      \
       S√≠        No
       ‚Üì         ‚Üì
    Guardar   Analizar
    modelo    m√°s profundo
```

### Ejemplo de Iteraci√≥n: Mejorar Evitaci√≥n de Obst√°culos

**Problema identificado:** El modelo no se desv√≠a suficientemente de obst√°culos.

**Soluci√≥n 1: Aumentar urgencia de evitaci√≥n en datos**

Modificar `train_nn_model.py` en la funci√≥n `generate_training_data()`:

```python
# ANTES (l√≠nea ~40):
if dist_to_obstacle < 1.0:
    linear_vel = 0.2
    angular_vel = 2.5 * np.sign(angle_to_obstacle)

# DESPU√âS (m√°s agresivo):
if dist_to_obstacle < 1.5:  # Aumentar rango de urgencia
    linear_vel = 0.15  # M√°s lento
    angular_vel = 2.8 * np.sign(angle_to_obstacle)  # Giro m√°s fuerte
```

**Soluci√≥n 2: Generar m√°s ejemplos de evitaci√≥n**

```python
# Aumentar proporci√≥n de ejemplos con obst√°culos cercanos
for _ in range(num_samples):
    # 30% de ejemplos con obst√°culos muy cercanos
    if np.random.random() < 0.3:
        dist_to_obstacle = np.random.uniform(0.1, 1.5)  # M√°s ejemplos cercanos
    else:
        dist_to_obstacle = np.random.uniform(0.1, 15.0)
```

**Soluci√≥n 3: Aumentar muestras de entrenamiento**

```python
# En main():
inputs, targets = generate_training_data(num_samples=10000)  # M√°s datos
```

---

## Ajuste de Hiperpar√°metros

### Tabla de Hiperpar√°metros y Efectos

| Hiperpar√°metro | Valor Actual | Aumentar | Disminuir |
|---------------|--------------|----------|-----------|
| **√âpocas** | 100 | M√°s entrenamiento, riesgo de sobreajuste | Menos entrenamiento, puede no converger |
| **Batch Size** | 32 | M√°s estable, m√°s memoria | Menos estable, m√°s r√°pido |
| **Learning Rate** | 0.001 | Convergencia m√°s r√°pida, puede oscilar | Convergencia m√°s lenta, m√°s estable |
| **Hidden Size 1** | 64 | M√°s capacidad, m√°s par√°metros | Menos capacidad, m√°s r√°pido |
| **Hidden Size 2** | 32 | M√°s capacidad, m√°s par√°metros | Menos capacidad, m√°s r√°pido |
| **Dropout** | 0.1 | M√°s regularizaci√≥n | Menos regularizaci√≥n |

### Gu√≠a de Ajuste por Problema

#### Problema: Modelo no aprende (p√©rdida no disminuye)

```python
# Soluciones:
1. Aumentar learning rate: 0.001 ‚Üí 0.002
2. Aumentar tama√±o de capas: 64 ‚Üí 128, 32 ‚Üí 64
3. Reducir dropout: 0.1 ‚Üí 0.05
4. Aumentar √©pocas: 100 ‚Üí 200
```

#### Problema: Modelo sobreajusta (p√©rdida aumenta al final)

```python
# Soluciones:
1. Aumentar dropout: 0.1 ‚Üí 0.2
2. Reducir learning rate: 0.001 ‚Üí 0.0005
3. Aumentar batch size: 32 ‚Üí 64
4. Reducir tama√±o de capas: 64 ‚Üí 48, 32 ‚Üí 24
```

#### Problema: Convergencia muy lenta

```python
# Soluciones:
1. Aumentar learning rate: 0.001 ‚Üí 0.002
2. Reducir √©pocas pero aumentar batch: 100 ‚Üí 150, 32 ‚Üí 64
3. Usar scheduler de learning rate
```

### Script de Entrenamiento con Hiperpar√°metros Configurables

Crea un archivo `train_with_params.py`:

```python
#!/usr/bin/env python3
"""
Script de entrenamiento con hiperpar√°metros configurables
Uso: python3 train_with_params.py --epochs 200 --lr 0.0005
"""

import argparse
from train_nn_model import generate_training_data, train_model, NeuralNetworkController
import torch

def main():
    parser = argparse.ArgumentParser(description='Entrenar modelo con par√°metros personalizados')
    parser.add_argument('--epochs', type=int, default=100, help='N√∫mero de √©pocas')
    parser.add_argument('--batch_size', type=int, default=32, help='Tama√±o del batch')
    parser.add_argument('--lr', type=float, default=0.001, help='Learning rate')
    parser.add_argument('--samples', type=int, default=5000, help='N√∫mero de muestras')
    parser.add_argument('--hidden1', type=int, default=64, help='Tama√±o capa oculta 1')
    parser.add_argument('--hidden2', type=int, default=32, help='Tama√±o capa oculta 2')
    parser.add_argument('--output', type=str, default='turtle_nn_model.pth', help='Nombre del archivo de salida')
    
    args = parser.parse_args()
    
    print("=" * 60)
    print("üß† Entrenamiento con Par√°metros Personalizados")
    print("=" * 60)
    print(f"√âpocas: {args.epochs}")
    print(f"Batch size: {args.batch_size}")
    print(f"Learning rate: {args.lr}")
    print(f"Muestras: {args.samples}")
    print(f"Arquitectura: 6 ‚Üí {args.hidden1} ‚Üí {args.hidden2} ‚Üí 2")
    print()
    
    # Generar datos
    print("üìä Generando datos...")
    inputs, targets = generate_training_data(num_samples=args.samples)
    print(f"‚úÖ {len(inputs)} ejemplos generados")
    
    # Crear modelo con arquitectura personalizada
    model = NeuralNetworkController(
        input_size=6,
        hidden_size1=args.hidden1,
        hidden_size2=args.hidden2,
        output_size=2
    )
    
    # Entrenar
    trained_model = train_model(
        model,
        inputs,
        targets,
        epochs=args.epochs,
        batch_size=args.batch_size,
        learning_rate=args.lr
    )
    
    # Guardar
    torch.save(trained_model.state_dict(), args.output)
    print(f"\nüíæ Modelo guardado en: {args.output}")

if __name__ == '__main__':
    main()
```

**Uso:**
```bash
# Entrenar con par√°metros personalizados
python3 train_with_params.py --epochs 200 --lr 0.0005 --samples 10000

# Entrenar con arquitectura m√°s grande
python3 train_with_params.py --hidden1 128 --hidden2 64 --epochs 150
```

---

## Mejora de Datos de Entrenamiento

### Estrategias para Mejorar los Datos

#### 1. Aumentar Diversidad de Escenarios

```python
def generate_training_data_improved(num_samples=5000):
    inputs = []
    targets = []
    
    # 40% escenarios con obst√°culos cercanos (cr√≠ticos)
    # 30% escenarios con obst√°culos medios
    # 30% escenarios sin obst√°culos cercanos
    
    for i in range(num_samples):
        if i < num_samples * 0.4:
            # Obst√°culos muy cercanos
            dist_to_obstacle = np.random.uniform(0.1, 1.5)
        elif i < num_samples * 0.7:
            # Obst√°culos medios
            dist_to_obstacle = np.random.uniform(1.5, 3.0)
        else:
            # Sin obst√°culos cercanos
            dist_to_obstacle = np.random.uniform(3.0, 15.0)
        
        # ... resto del c√≥digo
```

#### 2. A√±adir Penalizaci√≥n por Trayectorias Peligrosas

```python
# En las reglas heur√≠sticas, detectar si la trayectoria pasa cerca del obst√°culo
angle_to_goal = np.random.uniform(-math.pi, math.pi)
angle_to_obstacle = np.random.uniform(-math.pi, math.pi)

# Si la trayectoria hacia el objetivo pasa cerca del obst√°culo
angle_diff = abs(angle_to_goal - angle_to_obstacle)
if angle_diff < math.pi / 3 and dist_to_obstacle < 2.5:
    # Aumentar urgencia de evitaci√≥n
    linear_vel *= 0.7  # Reducir m√°s la velocidad
    angular_vel = 2.2 * np.sign(angle_to_obstacle)  # Giro m√°s agresivo
```

#### 3. A√±adir Ejemplos de Recuperaci√≥n

```python
# Ejemplos donde el robot est√° muy cerca y necesita escapar
if dist_to_obstacle < 0.3:
    # Escenario cr√≠tico: retroceder y girar
    linear_vel = -0.3  # Retroceder
    angular_vel = 3.0 * np.sign(angle_to_obstacle)  # Giro m√°ximo
```

#### 4. Balancear Datos por Distancia al Objetivo

```python
# Asegurar ejemplos en todas las distancias
if i % 3 == 0:
    dist_to_goal = np.random.uniform(0.1, 1.0)  # Cerca
elif i % 3 == 1:
    dist_to_goal = np.random.uniform(1.0, 5.0)  # Media
else:
    dist_to_goal = np.random.uniform(5.0, 15.0)  # Lejos
```

### Funci√≥n Mejorada de Generaci√≥n de Datos

Crea `train_nn_model_improved.py` con estas mejoras:

```python
def generate_training_data_improved(num_samples=10000):
    """
    Versi√≥n mejorada con m√°s diversidad y escenarios cr√≠ticos
    """
    inputs = []
    targets = []
    
    for i in range(num_samples):
        # Balancear escenarios
        scenario_type = np.random.choice(['critical', 'medium', 'normal'], 
                                        p=[0.3, 0.3, 0.4])
        
        if scenario_type == 'critical':
            # Escenarios cr√≠ticos: obst√°culo muy cercano
            dist_to_obstacle = np.random.uniform(0.1, 1.0)
            dist_to_goal = np.random.uniform(0.5, 10.0)
        elif scenario_type == 'medium':
            # Escenarios medios: obst√°culo a distancia media
            dist_to_obstacle = np.random.uniform(1.0, 3.0)
            dist_to_goal = np.random.uniform(1.0, 12.0)
        else:
            # Escenarios normales: sin obst√°culos cercanos
            dist_to_obstacle = np.random.uniform(3.0, 15.0)
            dist_to_goal = np.random.uniform(0.5, 15.0)
        
        # ... resto de la generaci√≥n con reglas mejoradas
```

---

## Debugging y Soluci√≥n de Problemas

### Problema: Modelo no se desv√≠a de obst√°culos

**Diagn√≥stico:**
```python
# A√±adir logging en control_loop para ver qu√© est√° pasando
def control_loop(self):
    # ... c√≥digo existente ...
    
    # DEBUG: Log cuando hay obst√°culo cercano
    if dist_to_obstacle < 2.0:
        self.get_logger().warn(
            f'üö® OBST√ÅCULO CERCANO! Dist: {dist_to_obstacle:.2f}, '
            f'Urgencia esperada: alta, '
            f'Velocidades: lin={linear_vel:.2f}, ang={angular_vel:.2f}'
        )
```

**Soluciones:**

1. **Aumentar peso de evitaci√≥n en entrenamiento:**
   ```python
   # En generate_training_data, hacer las reglas m√°s estrictas
   if dist_to_obstacle < 2.0:  # Aumentar rango
       linear_vel = 0.4  # M√°s conservador
       angular_vel = 2.5 * np.sign(angle_to_obstacle)
   ```

2. **Aumentar sensibilidad en el controlador:**
   ```python
   # En control_loop, ajustar umbral
   if dist_to_obstacle < 2.5:  # Detectar antes (era 2.0)
       # Forzar m√°s reducci√≥n de velocidad
       linear_vel *= 0.7
   ```

### Problema: Movimientos bruscos

**Soluci√≥n: Suavizar salidas**

```python
# En control_loop, a√±adir filtro de suavizado
if not hasattr(self, 'prev_linear_vel'):
    self.prev_linear_vel = 0.0
    self.prev_angular_vel = 0.0

# Suavizar con promedio m√≥vil (alpha = 0.7)
alpha = 0.7
linear_vel = alpha * linear_vel + (1 - alpha) * self.prev_linear_vel
angular_vel = alpha * angular_vel + (1 - alpha) * self.prev_angular_vel

self.prev_linear_vel = linear_vel
self.prev_angular_vel = angular_vel
```

### Problema: No llega a objetivos

**Soluci√≥n: Aumentar prioridad de navegaci√≥n**

```python
# En generate_training_data, cuando no hay obst√°culos:
if dist_to_obstacle > 3.0:
    # Aumentar velocidad hacia objetivo
    if dist_to_goal < 1.0:
        linear_vel = 0.6  # M√°s r√°pido cerca del objetivo
    elif dist_to_goal < 3.0:
        linear_vel = 1.4  # M√°s r√°pido en distancia media
    else:
        linear_vel = 1.8  # M√°s r√°pido cuando est√° lejos
```

---

## Checklist de Mejora Continua

### Antes de Cada Iteraci√≥n

- [ ] Identificar problema espec√≠fico a resolver
- [ ] Revisar logs de iteraci√≥n anterior
- [ ] Decidir qu√© cambiar (datos, hiperpar√°metros, o ambos)
- [ ] Hacer backup del modelo anterior: `cp turtle_nn_model.pth turtle_nn_model_backup.pth`

### Durante el Entrenamiento

- [ ] Verificar que la p√©rdida disminuye
- [ ] Observar que no hay sobreajuste
- [ ] Anotar p√©rdida final para comparaci√≥n

### Despu√©s del Entrenamiento

- [ ] Recompilar el paquete
- [ ] Copiar el modelo al directorio de instalaci√≥n
- [ ] Ejecutar y observar comportamiento
- [ ] Comparar con iteraci√≥n anterior
- [ ] Documentar resultados en log de iteraci√≥n

### M√©tricas de √âxito

- [ ] ‚úÖ Llega a objetivos > 90% de las veces
- [ ] ‚úÖ Evita obst√°culos > 95% de las veces
- [ ] ‚úÖ No se queda atascado
- [ ] ‚úÖ Movimientos suaves y naturales
- [ ] ‚úÖ Tiempo promedio de llegada razonable

---

## Ejemplo Completo de Iteraci√≥n

### Iteraci√≥n 1: Modelo Base

```bash
# Entrenar
python3 train_nn_model.py
# Resultado: P√©rdida final: 0.045

# Observaci√≥n: A veces no se desv√≠a de obst√°culos
```

### Iteraci√≥n 2: Mejorar Evitaci√≥n

```bash
# Modificar train_nn_model.py:
# - Aumentar rango de urgencia: 1.0 ‚Üí 1.5
# - Aumentar giro: 2.5 ‚Üí 2.8
# - 30% m√°s ejemplos con obst√°culos cercanos

python3 train_nn_model.py
# Resultado: P√©rdida final: 0.038

# Observaci√≥n: Mejor evitaci√≥n, pero movimientos m√°s bruscos
```

### Iteraci√≥n 3: Suavizar Movimientos

```bash
# A√±adir suavizado en control_loop
# Reducir learning rate: 0.001 ‚Üí 0.0008

python3 train_nn_model.py
# Resultado: P√©rdida final: 0.042

# Observaci√≥n: Movimientos m√°s suaves, evitaci√≥n mantenida
```

### Iteraci√≥n 4: Fine-tuning

```bash
# Aumentar muestras: 5000 ‚Üí 8000
# Aumentar √©pocas: 100 ‚Üí 150
# Learning rate scheduler

python3 train_nn_model.py
# Resultado: P√©rdida final: 0.031

# Observaci√≥n: Comportamiento √≥ptimo
```

---

## Recursos Adicionales

### Scripts √ötiles

1. **`compare_models.py`**: Compara dos modelos lado a lado
2. **`visualize_training.py`**: Genera gr√°ficas de p√©rdida
3. **`test_scenarios.py`**: Prueba el modelo en escenarios espec√≠ficos

### Comandos R√°pidos

```bash
# Entrenar y desplegar en un comando
python3 train_nn_model.py && \
cd /ros2_ws && \
colcon build --packages-select turtle_nn_control && \
cp src/turtle_nn_control/turtle_nn_control/turtle_nn_model.pth \
   install/turtle_nn_control/lib/python3.10/site-packages/turtle_nn_control/ && \
source install/setup.bash && \
echo "‚úÖ Listo para ejecutar: ros2 run turtle_nn_control nn_controller"
```

---

## Conclusi√≥n

El proceso de mejora iterativa requiere:

1. **Paciencia**: Cada iteraci√≥n puede tomar tiempo
2. **Observaci√≥n cuidadosa**: Identificar problemas espec√≠ficos
3. **Cambios incrementales**: No cambiar todo a la vez
4. **Documentaci√≥n**: Registrar cada iteraci√≥n
5. **Comparaci√≥n**: Comparar con iteraciones anteriores

Con esta gu√≠a, deber√≠as poder mejorar sistem√°ticamente el rendimiento del modelo hasta alcanzar un comportamiento √≥ptimo.

